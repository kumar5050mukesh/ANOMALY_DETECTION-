{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is anomaly detection and what is its purpose?\n",
    "\"\"\"\n",
    "Anomaly detection is the process of identifying patterns or data points that deviate significantly from the norm or expected\n",
    " behavior. The goal of anomaly detection is to identify unusual, rare, or suspicious events or behaviors that may be indicative\n",
    "  of a problem or potential threat.\n",
    "\n",
    "In other words, anomaly detection is the process of finding data points that are outliers in a given dataset, and it can be used\n",
    " for a variety of applications, such as fraud detection, intrusion detection, system health monitoring, and predictive maintenance.\n",
    "\n",
    "The purpose of anomaly detection is to identify and flag potentially problematic data points that may require further \n",
    "investigation or action. By identifying anomalies early, organizations can take proactive steps to address issues and \n",
    "prevent more serious problems from occurring. Additionally, anomaly detection can help organizations optimize their \n",
    "operations and improve overall efficiency by identifying areas where processes can be improved or streamlined.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What are the key challenges in anomaly detection?\n",
    "\"\"\"\n",
    "\n",
    "Anomaly detection is the process of identifying patterns or instances that deviate from the norm or expected behavior.\n",
    " While it can be a powerful tool for detecting unusual or fraudulent activity, there are several hurdles that can make \n",
    " it challenging to implement effectively. \n",
    "\n",
    "Lack of labeled data--- Anomaly detection algorithms often require labeled data to train the model. However, obtaining labeled\n",
    " data can be difficult or expensive, especially when dealing with rare events.\n",
    "\n",
    "Imbalanced data--- Anomaly detection datasets are often highly imbalanced, with a large number of normal instances and\n",
    " only a few anomalous instances. This can make it difficult for the algorithm to accurately detect anomalies.\n",
    "\n",
    "Data preprocessing--- Anomaly detection algorithms often require preprocessing steps to transform the data into a format \n",
    "suitable for analysis. This can be time-consuming and require expertise in data manipulation.\n",
    "\n",
    "False positives--- Anomaly detection algorithms can sometimes generate false positives, flagging normal instances as anomalies.\n",
    " This can be problematic, especially if it leads to unnecessary investigations or actions.\n",
    "\n",
    "Real-time detection--- Real-time anomaly detection can be challenging, especially when dealing with large volumes of data.\n",
    " The algorithm must be able to process data quickly and accurately, without compromising on the quality of the results.\n",
    "\n",
    "Interpretability--- Some anomaly detection algorithms can be difficult to interpret, making it hard to understand why a\n",
    " particular instance was flagged as an anomaly. This can make it challenging to take appropriate action based on the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\"\"\"\n",
    "\n",
    "\"\"\"Unsupervised anomaly detection and supervised anomaly detection are two different approaches used to identify anomalies in data. \n",
    "\n",
    "Unsupervised anomaly detection is used when the data is not labeled, and there are no prior examples of anomalies to learn from.\n",
    " This means that the algorithm must identify patterns in the data that deviate from the norm without any prior knowledge of what\n",
    "  constitutes an anomaly. Unsupervised anomaly detection methods include clustering-based methods, density-based methods, and \n",
    "  statistical methods.\n",
    "\n",
    "Supervised anomaly detection, on the other hand, uses labeled data to train a model to recognize anomalies. The model is trained\n",
    " on a dataset that contains both normal and anomalous instances. The goal is to learn the patterns that distinguish normal \n",
    " instances from anomalies. Once the model is trained, it can be used to identify anomalies in new, unseen data. \n",
    " Supervised anomaly detection methods include decision tree-based methods, rule-based methods, and deep learning-based methods.\n",
    "\n",
    "One key difference between the two approaches is that supervised anomaly detection requires labeled data,\n",
    " which can be time-consuming and expensive to obtain. In contrast, unsupervised anomaly detection can be used when\n",
    "  labeled data is not available, making it a more practical option in some situations.\n",
    "\n",
    "Another difference is that supervised anomaly detection is often more accurate than unsupervised anomaly detection\n",
    " because it is trained on labeled data. However, supervised anomaly detection is limited by the fact that it can \n",
    " only identify anomalies that are similar to the anomalies seen during training. In contrast, unsupervised anomaly \n",
    " detection can identify novel anomalies that have not been seen before, making it more flexible and adaptable to \n",
    " changing data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What are the main categories of anomaly detection algorithms?\n",
    "\"\"\"\n",
    "\n",
    "Anomaly detection algorithms can be broadly categorized into the following types:\n",
    "\n",
    "Statistical Methods--- These algorithms use statistical techniques such as probability density estimation, clustering, and\n",
    " regression analysis to identify anomalies. They assume that normal data points will follow a certain statistical pattern, \n",
    " and any data point that deviates significantly from that pattern is considered an anomaly.\n",
    "\n",
    "Machine Learning Methods--- These algorithms use supervised, unsupervised, or semi-supervised machine learning techniques to \n",
    "detect anomalies. Supervised learning algorithms are trained on labeled data to predict anomalies in new data, whereas \n",
    "unsupervised learning algorithms use clustering or density estimation techniques to identify unusual patterns in data.\n",
    " Semi-supervised learning algorithms combine elements of both supervised and unsupervised learning to detect anomalies.\n",
    "\n",
    "Deep Learning Methods--- These algorithms use deep neural networks to identify complex patterns in data. They are particularly\n",
    " useful for detecting anomalies in large and complex datasets, such as image, speech, or text data. Deep learning algorithms\n",
    "  can be supervised or unsupervised, depending on the availability of labeled data.\n",
    "\n",
    "Rule-Based Methods--- These algorithms use predefined rules to identify anomalies in data. Rules can be based on expert \n",
    "knowledge, domain-specific heuristics, or data-driven patterns. These methods are particularly useful in situations where \n",
    "the underlying statistical or machine learning models may not be able to capture all possible anomalies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\"\"\"Density assumption--- normal instances are more concentrated in the data space than anomalous instances.\n",
    "\n",
    "Distance assumption--- anomalous instances are far away from the normal instances in the data space.\n",
    "\n",
    "Local structure assumption--- normal instances exhibit a consistent local structure in the data space, whereas anomalous \n",
    "instances do not follow this pattern.\n",
    "\n",
    "Independence assumption--- each instance is independent of the others, and its attributes do not depend on the attributes\n",
    " of other instances.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\"\"\"The LOF score for a data point is computed as the ratio of the average local density of its k-nearest neighbors to its own\n",
    " local density. If the ratio is close to 1, then the point is similar in density to its neighbors and is not anomalous. \n",
    " If the ratio is greater than 1, then the point is less dense than its neighbors and is considered anomalous. The larger\n",
    "  the ratio, the more anomalous the point is considered to be.\n",
    "  The LOF algorithm computes the local density of a data point as the inverse of the average distance between the point and\n",
    "   its k-nearest neighbors. The k-nearest neighbors are the k points in the data set that are closest to the given data point.\n",
    "    The local density of a point is a measure of how close it is to its neighbors and how tightly the neighbors are clustered \n",
    "    together.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\"\"\"The Isolation Forest algorithm is a tree-based anomaly detection method that is based on the concept of isolating anomalies\n",
    " from the majority of the data. \n",
    "\n",
    "Number of trees or n_estimators--- This parameter controls the number of trees in the forest. A larger number of trees will\n",
    " increase the accuracy of the model but may also increase the training time and memory requirements.\n",
    "\n",
    "Sample size or max_samples--- This parameter controls the number of instances to be selected randomly from the dataset to construct\n",
    " each tree. A smaller sample size will result in more random splits and potentially faster training, but may also decrease\n",
    "  the accuracy of the model.\n",
    "\n",
    "Maximum depth or max_depth)--- This parameter controls the maximum depth of each tree in the forest. A deeper tree can capture\n",
    " more complex relationships in the data, but may also increase the risk of overfitting.\n",
    "\n",
    "Contamination---- This parameter represents the proportion of anomalous data points in the dataset. It is used to set the\n",
    " threshold for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score\n",
    "# using KNN with K=10?\n",
    "\"\"\" Its anomaly score would be 1 - (2/10) = 0.8. This is because the anomaly score is calculated\n",
    "  as 1 minus the ratio of the number of neighbors of the same class to the total number of neighbors.\n",
    "  \n",
    "  An anomaly score of 0.8 signifies that the data point is relatively more likely to be an anomaly compared to other\n",
    "   points in the dataset\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The anomaly score for the data point is: 1.0015050194857185\n"
     ]
    }
   ],
   "source": [
    "# Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the\n",
    "# anomaly score for a data point that has an average path length of 5.0 compared to the average path\n",
    "# length of the trees?\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = np.random.randn(3000, 10)\n",
    "iso_forest = IsolationForest(n_estimators=100, contamination='auto')\n",
    "\n",
    "iso_forest.fit(X)\n",
    "new_point = np.random.randn(1, 10)\n",
    "avg_path_length = np.mean(iso_forest.decision_function(new_point))\n",
    "n = X.shape[0]\n",
    "norm_factor = 2 * (np.log(n - 1) + 0.5772156649)\n",
    "\n",
    "\n",
    "anomaly_score = 2 ** (-avg_path_length / norm_factor)\n",
    "\n",
    "print(f\"The anomaly score for the data point is: {anomaly_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
